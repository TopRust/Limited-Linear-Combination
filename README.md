task mix0 train.py --name mix --seed 0
task mix1 train.py --name mix --seed 1
task mix2 train.py --name mix --seed 2
task mix3 train.py --name mix --seed 3
task mix4 train.py --name mix --seed 4
task mix5 train.py --name mix --seed 5
task mix6 train.py --name mix --seed 6
task mix7 train.py --name mix --seed 7
task mix8 train.py --name mix --seed 8
task mix9 train.py --name mix --seed 9
task mix10 train.py --name mix --seed 10
task mix11 train.py --name mix --seed 11


task l1r9_0 train.py --left 0.1 --right 0.9 --name lr --seed 0
task l1r9_1 train.py --left 0.1 --right 0.9 --name lr --seed 1
task l1r9_2 train.py --left 0.1 --right 0.9 --name lr --seed 2
task l2r8_0 train.py --left 0.2 --right 0.8 --name lr --seed 0
task l2r8_1 train.py --left 0.2 --right 0.8 --name lr --seed 1
task l2r8_2 train.py --left 0.2 --right 0.8 --name lr --seed 2
task l3r7_0 train.py --left 0.3 --right 0.7 --name lr --seed 0
task l3r7_1 train.py --left 0.3 --right 0.7 --name lr --seed 1
task l3r7_2 train.py --left 0.3 --right 0.7 --name lr --seed 2
task l4r6_0 train.py --left 0.4 --right 0.6 --name lr --seed 0
task l4r6_1 train.py --left 0.4 --right 0.6 --name lr --seed 1
task l4r6_2 train.py --left 0.4 --right 0.6 --name lr --seed 2

task l1r8_0 train.py --left 0.1 --right 0.8 --name lr --seed 0
task l1r8_1 train.py --left 0.1 --right 0.8 --name lr --seed 1
task l1r8_2 train.py --left 0.1 --right 0.8 --name lr --seed 2
task l1r7_0 train.py --left 0.1 --right 0.7 --name lr --seed 0
task l1r7_1 train.py --left 0.1 --right 0.7 --name lr --seed 1
task l1r7_2 train.py --left 0.1 --right 0.7 --name lr --seed 2
task l1r6_0 train.py --left 0.1 --right 0.6 --name lr --seed 0
task l1r6_1 train.py --left 0.1 --right 0.6 --name lr --seed 1
task l1r6_2 train.py --left 0.1 --right 0.6 --name lr --seed 2
task l1r5_0 train.py --left 0.1 --right 0.5 --name lr --seed 0
task l1r5_1 train.py --left 0.1 --right 0.5 --name lr --seed 1
task l1r5_2 train.py --left 0.1 --right 0.5 --name lr --seed 2


task l3r7_3 train.py --left 0.3 --right 0.7 --name l3r7 --seed 3
task l3r7_4 train.py --left 0.3 --right 0.7 --name l3r7 --seed 4
task l3r7_5 train.py --left 0.3 --right 0.7 --name l3r7 --seed 5
task l3r7_6 train.py --left 0.3 --right 0.7 --name l3r7 --seed 6
task l3r7_7 train.py --left 0.3 --right 0.7 --name l3r7 --seed 7
task l3r7_8 train.py --left 0.3 --right 0.7 --name l3r7 --seed 8
task l3r7_9 train.py --left 0.3 --right 0.7 --name l3r7 --seed 9
task l3r7_10 train.py --left 0.3 --right 0.7 --name l3r7 --seed 10
task l3r7_11 train.py --left 0.3 --right 0.7 --name l3r7 --seed 11

task l2r6_0 train.py --left 0.2 --right 0.6 --name l2r6 --seed 0
task l2r6_1 train.py --left 0.2 --right 0.6 --name l2r6 --seed 1
task l2r6_2 train.py --left 0.2 --right 0.6 --name l2r6 --seed 2
task l2r4_0 train.py --left 0.2 --right 0.4 --name l2r4 --seed 0
task l2r4_1 train.py --left 0.2 --right 0.4 --name l2r4 --seed 1
task l2r4_2 train.py --left 0.2 --right 0.4 --name l2r4 --seed 2

task ext0.02_3 train.py --extend 0.02 --name ext0.02 --seed 3
task ext0.02_4 train.py --extend 0.02 --name ext0.02 --seed 4
task ext0.02_5 train.py --extend 0.02 --name ext0.02 --seed 5
task ext0.02_6 train.py --extend 0.02 --name ext0.02 --seed 6
task ext0.02_7 train.py --extend 0.02 --name ext0.02 --seed 7
task ext0.02_8 train.py --extend 0.02 --name ext0.02 --seed 8
task ext0.02_9 train.py --extend 0.02 --name ext0.02 --seed 9
task ext0.02_10 train.py --extend 0.02 --name ext0.02 --seed 10
task ext0.02_11 train.py --extend 0.02 --name ext0.02 --seed 11

task ext0.03_3 train.py --extend 0.03 --name ext0.03 --seed 3
task ext0.03_4 train.py --extend 0.03 --name ext0.03 --seed 4
task ext0.03_5 train.py --extend 0.03 --name ext0.03 --seed 5
task ext0.03_6 train.py --extend 0.03 --name ext0.03 --seed 6
task ext0.03_7 train.py --extend 0.03 --name ext0.03 --seed 7
task ext0.03_8 train.py --extend 0.03 --name ext0.03 --seed 8
task ext0.03_9 train.py --extend 0.03 --name ext0.03 --seed 9
task ext0.03_10 train.py --extend 0.03 --name ext0.03 --seed 10
task ext0.03_11 train.py --extend 0.03 --name ext0.03 --seed 11

task ext0.025_0 train.py --extend 0.025 --name ext0.025 --seed 0
task ext0.025_1 train.py --extend 0.025 --name ext0.025 --seed 1
task ext0.025_2 train.py --extend 0.025 --name ext0.025 --seed 2
task ext0.025_3 train.py --extend 0.025 --name ext0.025 --seed 3
task ext0.025_4 train.py --extend 0.025 --name ext0.025 --seed 4
task ext0.025_5 train.py --extend 0.025 --name ext0.025 --seed 5
task ext0.025_6 train.py --extend 0.025 --name ext0.025 --seed 6
task ext0.025_7 train.py --extend 0.025 --name ext0.025 --seed 7
task ext0.025_8 train.py --extend 0.025 --name ext0.025 --seed 8
task ext0.025_9 train.py --extend 0.025 --name ext0.025 --seed 9
task ext0.025_10 train.py --extend 0.025 --name ext0.025 --seed 10
task ext0.025_11 train.py --extend 0.025 --name ext0.025 --seed 11

task ext0.023_0 train.py --extend 0.023 --name ext0.023 --seed 0 -r
task ext0.023_1 train.py --extend 0.023 --name ext0.023 --seed 1 -r
task ext0.023_2 train.py --extend 0.023 --name ext0.023 --seed 2 -r
task ext0.023_3 train.py --extend 0.023 --name ext0.023 --seed 3 -r 
task ext0.023_4 train.py --extend 0.023 --name ext0.023 --seed 4 -r
task ext0.023_5 train.py --extend 0.023 --name ext0.023 --seed 5 -r
task ext0.023_6 train.py --extend 0.023 --name ext0.023 --seed 6 -r
task ext0.023_7 train.py --extend 0.023 --name ext0.023 --seed 7 -r
task ext0.023_8 train.py --extend 0.023 --name ext0.023 --seed 8 -r
task ext0.023_9 train.py --extend 0.023 --name ext0.023 --seed 9 -r
task ext0.023_10 train.py --extend 0.023 --name ext0.023 --seed 10 -r 
task ext0.023_11 train.py --extend 0.023 --name ext0.023 --seed 11 -r

task ext0.027_0 train.py --extend 0.027 --name ext0.027 --seed 0
task ext0.027_1 train.py --extend 0.027 --name ext0.027 --seed 1
task ext0.027_2 train.py --extend 0.027 --name ext0.027 --seed 2
task ext0.027_3 train.py --extend 0.027 --name ext0.027 --seed 3
task ext0.027_4 train.py --extend 0.027 --name ext0.027 --seed 4
task ext0.027_5 train.py --extend 0.027 --name ext0.027 --seed 5
task ext0.027_6 train.py --extend 0.027 --name ext0.027 --seed 6
task ext0.027_7 train.py --extend 0.027 --name ext0.027 --seed 7
task ext0.027_8 train.py --extend 0.027 --name ext0.027 --seed 8
task ext0.027_9 train.py --extend 0.027 --name ext0.027 --seed 9
task ext0.027_10 train.py --extend 0.027 --name ext0.027 --seed 10
task ext0.027_11 train.py --extend 0.027 --name ext0.027 --seed 11


########

Epoch: 0
Loss: 1.943742 | Accuracy: 30.193133% (15096/50000)
11: 1.785491 | 21: 2.926596 | 12: 2.928253 | 22: 1.785491 | 1: 1.508405 | 2: 0.664845 | new: 2.173250 
train_research.py:247: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, targets = Variable(inputs, volatile=True), Variable(targets)
Loss: 0.000002 | Accuracy: 0.450900% (4509/1000000)
Saving..
best_accuracy: 0.4509

Epoch: 1
Loss: 1.679031 | Accuracy: 43.643086% (21821/50000)
11: 1.290334 | 21: 3.157607 | 12: 3.158817 | 22: 1.290334 | 1: 1.273684 | 2: 0.655901 | new: 1.929586 
Loss: 0.000002 | Accuracy: 0.576000% (5760/1000000)
Saving..
best_accuracy: 0.576

Epoch: 2
Loss: 1.524575 | Accuracy: 50.740773% (25370/50000)
11: 1.075563 | 21: 3.349406 | 12: 3.348414 | 22: 1.075563 | 1: 1.183944 | 2: 0.633231 | new: 1.817175 
Loss: 0.000002 | Accuracy: 0.607000% (6070/1000000)
Saving..
best_accuracy: 0.607

Epoch: 3
Loss: 1.421496 | Accuracy: 55.224703% (27612/50000)
11: 0.917647 | 21: 3.432472 | 12: 3.424075 | 22: 0.917647 | 1: 1.099066 | 2: 0.639172 | new: 1.738238 
Loss: 0.000001 | Accuracy: 0.702400% (7024/1000000)
Saving..
best_accuracy: 0.7024

Epoch: 4
Loss: 1.357467 | Accuracy: 57.624898% (28812/50000)
11: 0.820843 | 21: 3.460761 | 12: 3.450489 | 22: 0.820843 | 1: 1.051288 | 2: 0.636333 | new: 1.687621 
Loss: 0.000001 | Accuracy: 0.775800% (7758/1000000)
Saving..
best_accuracy: 0.7758

Epoch: 5
Loss: 1.286742 | Accuracy: 60.249449% (30124/50000)
11: 0.736760 | 21: 3.533184 | 12: 3.524731 | 22: 0.736760 | 1: 0.997424 | 2: 0.620558 | new: 1.617982 
Loss: 0.000001 | Accuracy: 0.804100% (8041/1000000)
Saving..
best_accuracy: 0.8041

Epoch: 6
Loss: 1.281931 | Accuracy: 60.520465% (30260/50000)
11: 0.695600 | 21: 3.537752 | 12: 3.524705 | 22: 0.695600 | 1: 0.986691 | 2: 0.647845 | new: 1.634536 
Loss: 0.000001 | Accuracy: 0.783200% (7832/1000000)
best_accuracy: 0.8041

Epoch: 7
Loss: 1.260244 | Accuracy: 61.340258% (30670/50000)
11: 0.653530 | 21: 3.528799 | 12: 3.516224 | 22: 0.653530 | 1: 0.968223 | 2: 0.651419 | new: 1.619642 
Loss: 0.000001 | Accuracy: 0.804400% (8044/1000000)
Saving..
best_accuracy: 0.8044

Epoch: 8
Loss: 1.233105 | Accuracy: 62.203582% (31101/50000)
11: 0.625171 | 21: 3.580982 | 12: 3.571978 | 22: 0.625171 | 1: 0.951864 | 2: 0.646653 | new: 1.598517 
Loss: 0.000001 | Accuracy: 0.811400% (8114/1000000)
Saving..
best_accuracy: 0.8114

Epoch: 9
Loss: 1.208137 | Accuracy: 63.020441% (31510/50000)
11: 0.598369 | 21: 3.616842 | 12: 3.604098 | 22: 0.598369 | 1: 0.940412 | 2: 0.646302 | new: 1.586715 
Loss: 0.000001 | Accuracy: 0.824900% (8249/1000000)
Saving..
best_accuracy: 0.8249

Epoch: 10
Loss: 1.187242 | Accuracy: 63.872691% (31936/50000)
11: 0.577861 | 21: 3.619129 | 12: 3.606899 | 22: 0.577861 | 1: 0.928984 | 2: 0.643953 | new: 1.572937 
Loss: 0.000001 | Accuracy: 0.825100% (8251/1000000)
Saving..
best_accuracy: 0.8251

Epoch: 11
Loss: 1.190790 | Accuracy: 63.927465% (31963/50000)
11: 0.558334 | 21: 3.610484 | 12: 3.591004 | 22: 0.558334 | 1: 0.926876 | 2: 0.655159 | new: 1.582036 
Loss: 0.000001 | Accuracy: 0.849600% (8496/1000000)
Saving..
best_accuracy: 0.8496

Epoch: 12
Loss: 1.169565 | Accuracy: 65.024074% (32512/50000)
11: 0.540957 | 21: 3.623996 | 12: 3.607665 | 22: 0.540957 | 1: 0.916926 | 2: 0.649032 | new: 1.565958 
Loss: 0.000001 | Accuracy: 0.856800% (8568/1000000)
Saving..
best_accuracy: 0.8568

Epoch: 13
Loss: 1.132515 | Accuracy: 66.243508% (33121/50000)
11: 0.517650 | 21: 3.678805 | 12: 3.665454 | 22: 0.517650 | 1: 0.898513 | 2: 0.633116 | new: 1.531628 
Loss: 0.000001 | Accuracy: 0.861100% (8611/1000000)
Saving..
best_accuracy: 0.8611

Epoch: 14
Loss: 1.122092 | Accuracy: 66.139625% (33069/50000)
11: 0.506768 | 21: 3.687556 | 12: 3.672390 | 22: 0.506768 | 1: 0.892479 | 2: 0.637940 | new: 1.530419 
Loss: 0.000001 | Accuracy: 0.875600% (8756/1000000)
Saving..
best_accuracy: 0.8756

Epoch: 15
Loss: 1.084442 | Accuracy: 67.846664% (33923/50000)
11: 0.475008 | 21: 3.696068 | 12: 3.689706 | 22: 0.475008 | 1: 0.860056 | 2: 0.611718 | new: 1.471774 
Loss: 0.000001 | Accuracy: 0.825500% (8255/1000000)
best_accuracy: 0.8756

Epoch: 16
Loss: 1.120701 | Accuracy: 66.357484% (33178/50000)
11: 0.485530 | 21: 3.690883 | 12: 3.675112 | 22: 0.485530 | 1: 0.890971 | 2: 0.651563 | new: 1.542533 
Loss: 0.000001 | Accuracy: 0.864700% (8647/1000000)
best_accuracy: 0.8756

Epoch: 17
Loss: 1.089086 | Accuracy: 67.270047% (33635/50000)
11: 0.468771 | 21: 3.712553 | 12: 3.709640 | 22: 0.468771 | 1: 0.869338 | 2: 0.634932 | new: 1.504271 
Loss: 0.000001 | Accuracy: 0.877500% (8775/1000000)
Saving..
best_accuracy: 0.8775

Epoch: 18
Loss: 1.140903 | Accuracy: 65.235508% (32617/50000)
11: 0.478376 | 21: 3.679436 | 12: 3.671968 | 22: 0.478376 | 1: 0.899475 | 2: 0.682054 | new: 1.581529 
Loss: 0.000001 | Accuracy: 0.856400% (8564/1000000)
best_accuracy: 0.8775

Epoch: 19
Loss: 1.116164 | Accuracy: 66.210430% (33105/50000)
11: 0.468322 | 21: 3.703377 | 12: 3.681368 | 22: 0.468322 | 1: 0.890638 | 2: 0.667273 | new: 1.557911 
Loss: 0.000001 | Accuracy: 0.887400% (8874/1000000)
Saving..
best_accuracy: 0.8874

Epoch: 20
Loss: 1.083079 | Accuracy: 67.713219% (33856/50000)
11: 0.445258 | 21: 3.724346 | 12: 3.701582 | 22: 0.445258 | 1: 0.870118 | 2: 0.647543 | new: 1.517661 
Loss: 0.000001 | Accuracy: 0.858000% (8580/1000000)
best_accuracy: 0.8874

Epoch: 21
Loss: 1.085534 | Accuracy: 67.406945% (33703/50000)
11: 0.436798 | 21: 3.730875 | 12: 3.722041 | 22: 0.436798 | 1: 0.867021 | 2: 0.657419 | new: 1.524440 
Loss: 0.000001 | Accuracy: 0.854700% (8547/1000000)
best_accuracy: 0.8874

Epoch: 22
Loss: 1.087599 | Accuracy: 67.215922% (33607/50000)
11: 0.436030 | 21: 3.760358 | 12: 3.743203 | 22: 0.436030 | 1: 0.876549 | 2: 0.666585 | new: 1.543134 
Loss: 0.000001 | Accuracy: 0.881000% (8810/1000000)
best_accuracy: 0.8874

Epoch: 23
Loss: 1.071365 | Accuracy: 67.864219% (33932/50000)
11: 0.428928 | 21: 3.731679 | 12: 3.722001 | 22: 0.428928 | 1: 0.861536 | 2: 0.653286 | new: 1.514822 
Loss: 0.000001 | Accuracy: 0.853100% (8531/1000000)
best_accuracy: 0.8874

Epoch: 24
Loss: 1.067583 | Accuracy: 68.213586% (34106/50000)
11: 0.427616 | 21: 3.741848 | 12: 3.730495 | 22: 0.427616 | 1: 0.860144 | 2: 0.650225 | new: 1.510369 
Loss: 0.000001 | Accuracy: 0.868300% (8683/1000000)
best_accuracy: 0.8874

Epoch: 25
Loss: 1.060508 | Accuracy: 68.114414% (34057/50000)
11: 0.417094 | 21: 3.774163 | 12: 3.755841 | 22: 0.417094 | 1: 0.860349 | 2: 0.656360 | new: 1.516709 
Loss: 0.000001 | Accuracy: 0.879100% (8791/1000000)
best_accuracy: 0.8874

Epoch: 26
Loss: 1.070439 | Accuracy: 67.645945% (33822/50000)
11: 0.414410 | 21: 3.781697 | 12: 3.758923 | 22: 0.414410 | 1: 0.869409 | 2: 0.671288 | new: 1.540697 
Loss: 0.000001 | Accuracy: 0.871000% (8710/1000000)
best_accuracy: 0.8874

Epoch: 27
Loss: 1.046255 | Accuracy: 68.791891% (34395/50000)
11: 0.410562 | 21: 3.785451 | 12: 3.770030 | 22: 0.410562 | 1: 0.859155 | 2: 0.654664 | new: 1.513819 
Loss: 0.000001 | Accuracy: 0.879900% (8799/1000000)
best_accuracy: 0.8874

Epoch: 28
Loss: 1.073963 | Accuracy: 67.725547% (33862/50000)
11: 0.408327 | 21: 3.751693 | 12: 3.727668 | 22: 0.408327 | 1: 0.869145 | 2: 0.674185 | new: 1.543330 
Loss: 0.000001 | Accuracy: 0.877400% (8774/1000000)
best_accuracy: 0.8874

Epoch: 29
Loss: 1.054550 | Accuracy: 68.161906% (34080/50000)
11: 0.395365 | 21: 3.797297 | 12: 3.776026 | 22: 0.395365 | 1: 0.860830 | 2: 0.669738 | new: 1.530568 
Loss: 0.000001 | Accuracy: 0.873100% (8731/1000000)
best_accuracy: 0.8874

Epoch: 30
Loss: 1.069361 | Accuracy: 67.452008% (33726/50000)
11: 0.408237 | 21: 3.808940 | 12: 3.789477 | 22: 0.408237 | 1: 0.880416 | 2: 0.686406 | new: 1.566823 
Loss: 0.000001 | Accuracy: 0.897600% (8976/1000000)
Saving..
best_accuracy: 0.8976

Epoch: 31
Loss: 1.041137 | Accuracy: 68.444266% (34222/50000)
11: 0.401142 | 21: 3.781466 | 12: 3.770954 | 22: 0.401142 | 1: 0.856687 | 2: 0.664367 | new: 1.521054 
Loss: 0.000001 | Accuracy: 0.888200% (8882/1000000)
best_accuracy: 0.8976

Epoch: 32
Loss: 1.043719 | Accuracy: 68.739195% (34369/50000)
11: 0.394310 | 21: 3.780998 | 12: 3.761687 | 22: 0.394310 | 1: 0.857041 | 2: 0.663884 | new: 1.520925 
Loss: 0.000001 | Accuracy: 0.883000% (8830/1000000)
best_accuracy: 0.8976

Epoch: 33
Loss: 1.052701 | Accuracy: 68.361695% (34180/50000)
11: 0.393064 | 21: 3.799050 | 12: 3.787743 | 22: 0.393064 | 1: 0.865463 | 2: 0.677469 | new: 1.542931 
Loss: 0.000001 | Accuracy: 0.906500% (9065/1000000)
Saving..
best_accuracy: 0.9065

Epoch: 34
Loss: 1.028104 | Accuracy: 69.370031% (34685/50000)
11: 0.377345 | 21: 3.797955 | 12: 3.792066 | 22: 0.377345 | 1: 0.844396 | 2: 0.660317 | new: 1.504713 
Loss: 0.000001 | Accuracy: 0.893200% (8932/1000000)
best_accuracy: 0.9065

Epoch: 35
Loss: 1.011204 | Accuracy: 69.656711% (34828/50000)
11: 0.378640 | 21: 3.804776 | 12: 3.805343 | 22: 0.378640 | 1: 0.835935 | 2: 0.647409 | new: 1.483343 
Loss: 0.000001 | Accuracy: 0.897900% (8979/1000000)
best_accuracy: 0.9065

Epoch: 36
Loss: 1.009076 | Accuracy: 69.841773% (34920/50000)
11: 0.371304 | 21: 3.816598 | 12: 3.787149 | 22: 0.371304 | 1: 0.838743 | 2: 0.647997 | new: 1.486740 
Loss: 0.000001 | Accuracy: 0.878100% (8781/1000000)
best_accuracy: 0.9065

Epoch: 37
Loss: 1.016725 | Accuracy: 69.700195% (34850/50000)
11: 0.366845 | 21: 3.817503 | 12: 3.796175 | 22: 0.366845 | 1: 0.842676 | 2: 0.659816 | new: 1.502492 
Loss: 0.000001 | Accuracy: 0.896800% (8968/1000000)
best_accuracy: 0.9065

Epoch: 38
Loss: 1.039194 | Accuracy: 68.953359% (34476/50000)
11: 0.370493 | 21: 3.798416 | 12: 3.772440 | 22: 0.370493 | 1: 0.854411 | 2: 0.676608 | new: 1.531018 
Loss: 0.000001 | Accuracy: 0.898000% (8980/1000000)
best_accuracy: 0.9065

Epoch: 39
Loss: 1.026570 | Accuracy: 69.072570% (34536/50000)
11: 0.373492 | 21: 3.800945 | 12: 3.784956 | 22: 0.373492 | 1: 0.848410 | 2: 0.667383 | new: 1.515794 
Loss: 0.000001 | Accuracy: 0.900500% (9005/1000000)
best_accuracy: 0.9065

Epoch: 40
Loss: 1.043895 | Accuracy: 68.008039% (34004/50000)
11: 0.377548 | 21: 3.811146 | 12: 3.789348 | 22: 0.377548 | 1: 0.863468 | 2: 0.689107 | new: 1.552575 
Loss: 0.000001 | Accuracy: 0.902400% (9024/1000000)
best_accuracy: 0.9065

Epoch: 41
Loss: 0.995002 | Accuracy: 70.623812% (35311/50000)
11: 0.360100 | 21: 3.819931 | 12: 3.810979 | 22: 0.360100 | 1: 0.828682 | 2: 0.644935 | new: 1.473617 
Loss: 0.000001 | Accuracy: 0.898400% (8984/1000000)
best_accuracy: 0.9065

Epoch: 42
Loss: 1.028512 | Accuracy: 68.841242% (34420/50000)
11: 0.371745 | 21: 3.824667 | 12: 3.801873 | 22: 0.371745 | 1: 0.856240 | 2: 0.677979 | new: 1.534220 
Loss: 0.000001 | Accuracy: 0.880100% (8801/1000000)
best_accuracy: 0.9065

Epoch: 43
Loss: 0.997690 | Accuracy: 70.166336% (35083/50000)
11: 0.359693 | 21: 3.837339 | 12: 3.828565 | 22: 0.359693 | 1: 0.835399 | 2: 0.657719 | new: 1.493118 
Loss: 0.000001 | Accuracy: 0.880500% (8805/1000000)
best_accuracy: 0.9065

Epoch: 44
Loss: 1.002276 | Accuracy: 69.416680% (34708/50000)
11: 0.359585 | 21: 3.827161 | 12: 3.811613 | 22: 0.359585 | 1: 0.836382 | 2: 0.662574 | new: 1.498956 
Loss: 0.000001 | Accuracy: 0.903800% (9038/1000000)
best_accuracy: 0.9065

Epoch: 45
Loss: 1.020987 | Accuracy: 68.836727% (34418/50000)
11: 0.361153 | 21: 3.830671 | 12: 3.819349 | 22: 0.361153 | 1: 0.850349 | 2: 0.681858 | new: 1.532207 
Loss: 0.000001 | Accuracy: 0.896900% (8969/1000000)
best_accuracy: 0.9065

Epoch: 46
Loss: 0.995229 | Accuracy: 70.197523% (35098/50000)
11: 0.345537 | 21: 3.849280 | 12: 3.829939 | 22: 0.345537 | 1: 0.833640 | 2: 0.661328 | new: 1.494968 
Loss: 0.000001 | Accuracy: 0.893500% (8935/1000000)
best_accuracy: 0.9065

Epoch: 47
Loss: 0.998245 | Accuracy: 70.047617% (35023/50000)
11: 0.349567 | 21: 3.847459 | 12: 3.830285 | 22: 0.349567 | 1: 0.836203 | 2: 0.662574 | new: 1.498778 
Loss: 0.000001 | Accuracy: 0.907000% (9070/1000000)
Saving..
best_accuracy: 0.907

Epoch: 48
Loss: 1.004637 | Accuracy: 69.569187% (34784/50000)
11: 0.353659 | 21: 3.847678 | 12: 3.825870 | 22: 0.353659 | 1: 0.843722 | 2: 0.669443 | new: 1.513166 
Loss: 0.000001 | Accuracy: 0.874900% (8749/1000000)
best_accuracy: 0.907

Epoch: 49
Loss: 1.019060 | Accuracy: 69.156656% (34578/50000)
11: 0.363519 | 21: 3.812719 | 12: 3.800225 | 22: 0.363519 | 1: 0.855508 | 2: 0.683683 | new: 1.539191 
Loss: 0.000001 | Accuracy: 0.905800% (9058/1000000)
best_accuracy: 0.907

Epoch: 50
Loss: 0.987943 | Accuracy: 70.314445% (35157/50000)
11: 0.345710 | 21: 3.870581 | 12: 3.856155 | 22: 0.345710 | 1: 0.830364 | 2: 0.660689 | new: 1.491054 
Loss: 0.000001 | Accuracy: 0.897900% (8979/1000000)
best_accuracy: 0.907

Epoch: 51
Loss: 0.994178 | Accuracy: 70.166266% (35083/50000)
11: 0.343303 | 21: 3.835515 | 12: 3.813783 | 22: 0.343303 | 1: 0.833775 | 2: 0.664157 | new: 1.497932 
Loss: 0.000001 | Accuracy: 0.907900% (9079/1000000)
Saving..
best_accuracy: 0.9079

Epoch: 52
Loss: 0.979496 | Accuracy: 70.538875% (35269/50000)
11: 0.340571 | 21: 3.837678 | 12: 3.820550 | 22: 0.340571 | 1: 0.825481 | 2: 0.655371 | new: 1.480852 
Loss: 0.000001 | Accuracy: 0.904900% (9049/1000000)
best_accuracy: 0.9079

Epoch: 53
Loss: 0.987257 | Accuracy: 70.313641% (35156/50000)
11: 0.339194 | 21: 3.852818 | 12: 3.833299 | 22: 0.339194 | 1: 0.829078 | 2: 0.661665 | new: 1.490743 
Loss: 0.000001 | Accuracy: 0.911600% (9116/1000000)
Saving..
best_accuracy: 0.9116

Epoch: 54
Loss: 0.986130 | Accuracy: 70.537937% (35268/50000)
11: 0.345067 | 21: 3.844640 | 12: 3.823105 | 22: 0.345067 | 1: 0.832632 | 2: 0.660975 | new: 1.493607 
Loss: 0.000001 | Accuracy: 0.893800% (8938/1000000)
best_accuracy: 0.9116

Epoch: 55
Loss: 0.971736 | Accuracy: 71.215727% (35607/50000)
11: 0.335378 | 21: 3.846212 | 12: 3.833340 | 22: 0.335378 | 1: 0.821581 | 2: 0.652648 | new: 1.474229 
Loss: 0.000001 | Accuracy: 0.919900% (9199/1000000)
Saving..
best_accuracy: 0.9199

Epoch: 56
Loss: 0.978832 | Accuracy: 70.272023% (35136/50000)
11: 0.341912 | 21: 3.853617 | 12: 3.843067 | 22: 0.341912 | 1: 0.826852 | 2: 0.661560 | new: 1.488412 
Loss: 0.000001 | Accuracy: 0.895900% (8959/1000000)
best_accuracy: 0.9199

Epoch: 57
Loss: 0.989517 | Accuracy: 70.228461% (35114/50000)
11: 0.341832 | 21: 3.828103 | 12: 3.812385 | 22: 0.341832 | 1: 0.832273 | 2: 0.664769 | new: 1.497042 
Loss: 0.000001 | Accuracy: 0.894000% (8940/1000000)
best_accuracy: 0.9199

Epoch: 58
Loss: 0.991147 | Accuracy: 69.949156% (34974/50000)
11: 0.338661 | 21: 3.866201 | 12: 3.849914 | 22: 0.338661 | 1: 0.840422 | 2: 0.678358 | new: 1.518780 
Loss: 0.000001 | Accuracy: 0.915900% (9159/1000000)
best_accuracy: 0.9199

Epoch: 59
Loss: 0.994095 | Accuracy: 69.890391% (34945/50000)
11: 0.333658 | 21: 3.875306 | 12: 3.849189 | 22: 0.333658 | 1: 0.843546 | 2: 0.679610 | new: 1.523157 
Loss: 0.000001 | Accuracy: 0.897400% (8974/1000000)
best_accuracy: 0.9199

Epoch: 60
Loss: 0.996965 | Accuracy: 70.229391% (35114/50000)
11: 0.341660 | 21: 3.832525 | 12: 3.808850 | 22: 0.341660 | 1: 0.840427 | 2: 0.671643 | new: 1.512070 
Loss: 0.000001 | Accuracy: 0.893200% (8932/1000000)
best_accuracy: 0.9199

Epoch: 61
Loss: 0.998939 | Accuracy: 69.476984% (34738/50000)
11: 0.339260 | 21: 3.880395 | 12: 3.860630 | 22: 0.339260 | 1: 0.847998 | 2: 0.686606 | new: 1.534604 
Loss: 0.000001 | Accuracy: 0.908700% (9087/1000000)
best_accuracy: 0.9199

Epoch: 62
Loss: 0.968798 | Accuracy: 71.207992% (35603/50000)
11: 0.332995 | 21: 3.867151 | 12: 3.844431 | 22: 0.332995 | 1: 0.829272 | 2: 0.658546 | new: 1.487817 
Loss: 0.000001 | Accuracy: 0.905000% (9050/1000000)
best_accuracy: 0.9199

Epoch: 63
Loss: 0.966546 | Accuracy: 70.896234% (35448/50000)
11: 0.326151 | 21: 3.873224 | 12: 3.859090 | 22: 0.326151 | 1: 0.820378 | 2: 0.659722 | new: 1.480100 
Loss: 0.000001 | Accuracy: 0.883900% (8839/1000000)
best_accuracy: 0.9199

Epoch: 64
Loss: 0.988451 | Accuracy: 69.811352% (34905/50000)
11: 0.342670 | 21: 3.840902 | 12: 3.825283 | 22: 0.342670 | 1: 0.839510 | 2: 0.676961 | new: 1.516472 
Loss: 0.000001 | Accuracy: 0.898000% (8980/1000000)
best_accuracy: 0.9199

Epoch: 65
Loss: 0.959047 | Accuracy: 70.877188% (35438/50000)
11: 0.323099 | 21: 3.898441 | 12: 3.878621 | 22: 0.323099 | 1: 0.820594 | 2: 0.658269 | new: 1.478863 
Loss: 0.000001 | Accuracy: 0.909800% (9098/1000000)
best_accuracy: 0.9199

Epoch: 66
Loss: 0.963364 | Accuracy: 70.627789% (35313/50000)
11: 0.328023 | 21: 3.878584 | 12: 3.864618 | 22: 0.328023 | 1: 0.822728 | 2: 0.663172 | new: 1.485900 
Loss: 0.000001 | Accuracy: 0.905300% (9053/1000000)
best_accuracy: 0.9199

Epoch: 67
Loss: 0.969529 | Accuracy: 70.788617% (35394/50000)
11: 0.330234 | 21: 3.891386 | 12: 3.870516 | 22: 0.330233 | 1: 0.830584 | 2: 0.666565 | new: 1.497149 
Loss: 0.000001 | Accuracy: 0.895800% (8958/1000000)
best_accuracy: 0.9199

Epoch: 68
Loss: 0.959424 | Accuracy: 71.044961% (35522/50000)
11: 0.324972 | 21: 3.887433 | 12: 3.869564 | 22: 0.324972 | 1: 0.823734 | 2: 0.660278 | new: 1.484012 
Loss: 0.000001 | Accuracy: 0.898400% (8984/1000000)
best_accuracy: 0.9199

Epoch: 69
Loss: 0.967094 | Accuracy: 70.804789% (35402/50000)
11: 0.325776 | 21: 3.901590 | 12: 3.891273 | 22: 0.325776 | 1: 0.825292 | 2: 0.666597 | new: 1.491889 
Loss: 0.000001 | Accuracy: 0.905200% (9052/1000000)
best_accuracy: 0.9199

Epoch: 70
Loss: 0.940790 | Accuracy: 71.795609% (35897/50000)
11: 0.320729 | 21: 3.910793 | 12: 3.892189 | 22: 0.320729 | 1: 0.806951 | 2: 0.642847 | new: 1.449798 
Loss: 0.000001 | Accuracy: 0.902600% (9026/1000000)
best_accuracy: 0.9199

Epoch: 71
Loss: 0.960804 | Accuracy: 71.366812% (35683/50000)
11: 0.322286 | 21: 3.857879 | 12: 3.837586 | 22: 0.322286 | 1: 0.819579 | 2: 0.657789 | new: 1.477368 
Loss: 0.000001 | Accuracy: 0.914700% (9147/1000000)
best_accuracy: 0.9199

Epoch: 72
Loss: 0.980692 | Accuracy: 70.062469% (35031/50000)
11: 0.331735 | 21: 3.882036 | 12: 3.863065 | 22: 0.331735 | 1: 0.839923 | 2: 0.680518 | new: 1.520442 
Loss: 0.000001 | Accuracy: 0.911000% (9110/1000000)
best_accuracy: 0.9199

Epoch: 73
Loss: 0.968183 | Accuracy: 70.292477% (35146/50000)
11: 0.327737 | 21: 3.906687 | 12: 3.896072 | 22: 0.327737 | 1: 0.834858 | 2: 0.678733 | new: 1.513590 
Loss: 0.000001 | Accuracy: 0.919100% (9191/1000000)
best_accuracy: 0.9199

Epoch: 74
Loss: 0.988103 | Accuracy: 69.563180% (34781/50000)
11: 0.338840 | 21: 3.893245 | 12: 3.880437 | 22: 0.338840 | 1: 0.850351 | 2: 0.691524 | new: 1.541875 
Loss: 0.000001 | Accuracy: 0.908000% (9080/1000000)
best_accuracy: 0.9199

Epoch: 75
Loss: 0.960286 | Accuracy: 70.777477% (35388/50000)
11: 0.323765 | 21: 3.876813 | 12: 3.864736 | 22: 0.323765 | 1: 0.824614 | 2: 0.667430 | new: 1.492045 
Loss: 0.000001 | Accuracy: 0.904000% (9040/1000000)
best_accuracy: 0.9199

Epoch: 76
Loss: 0.985177 | Accuracy: 69.362930% (34681/50000)
11: 0.332871 | 21: 3.888619 | 12: 3.867410 | 22: 0.332871 | 1: 0.847048 | 2: 0.692510 | new: 1.539558 
Loss: 0.000001 | Accuracy: 0.907200% (9072/1000000)
best_accuracy: 0.9199

Epoch: 77
Loss: 1.000508 | Accuracy: 69.024336% (34512/50000)
11: 0.331850 | 21: 3.867111 | 12: 3.851382 | 22: 0.331850 | 1: 0.852973 | 2: 0.702670 | new: 1.555643 
Loss: 0.000001 | Accuracy: 0.911200% (9112/1000000)
best_accuracy: 0.9199

Epoch: 78
Loss: 0.959494 | Accuracy: 71.013250% (35506/50000)
11: 0.322268 | 21: 3.927585 | 12: 3.904578 | 22: 0.322268 | 1: 0.832727 | 2: 0.672473 | new: 1.505200 
Loss: 0.000001 | Accuracy: 0.887200% (8872/1000000)
best_accuracy: 0.9199

Epoch: 79
Loss: 0.971633 | Accuracy: 70.320531% (35160/50000)
11: 0.326298 | 21: 3.923863 | 12: 3.908412 | 22: 0.326298 | 1: 0.843398 | 2: 0.686225 | new: 1.529623 
Loss: 0.000001 | Accuracy: 0.892700% (8927/1000000)
best_accuracy: 0.9199

Epoch: 80
Loss: 0.950772 | Accuracy: 71.132969% (35566/50000)
11: 0.319634 | 21: 3.894239 | 12: 3.886311 | 22: 0.319634 | 1: 0.820571 | 2: 0.663125 | new: 1.483696 
Loss: 0.000001 | Accuracy: 0.907900% (9079/1000000)
best_accuracy: 0.9199

Epoch: 81
Loss: 0.938804 | Accuracy: 71.920516% (35960/50000)
11: 0.309373 | 21: 3.930196 | 12: 3.913021 | 22: 0.309373 | 1: 0.812296 | 2: 0.655272 | new: 1.467568 
Loss: 0.000001 | Accuracy: 0.902400% (9024/1000000)
best_accuracy: 0.9199

Epoch: 82
Loss: 0.929295 | Accuracy: 71.719297% (35859/50000)
11: 0.307393 | 21: 3.941987 | 12: 3.932179 | 22: 0.307393 | 1: 0.805705 | 2: 0.651544 | new: 1.457249 
Loss: 0.000001 | Accuracy: 0.909500% (9095/1000000)
best_accuracy: 0.9199

Epoch: 83
Loss: 0.975153 | Accuracy: 70.285242% (35142/50000)
11: 0.321982 | 21: 3.905264 | 12: 3.885790 | 22: 0.321982 | 1: 0.840147 | 2: 0.684476 | new: 1.524623 
Loss: 0.000001 | Accuracy: 0.912000% (9120/1000000)
best_accuracy: 0.9199

Epoch: 84
Loss: 0.947231 | Accuracy: 71.186969% (35593/50000)
11: 0.305949 | 21: 3.927087 | 12: 3.910143 | 22: 0.305949 | 1: 0.819092 | 2: 0.668035 | new: 1.487127 
Loss: 0.000001 | Accuracy: 0.886800% (8868/1000000)
best_accuracy: 0.9199

Epoch: 85
Loss: 0.956662 | Accuracy: 71.228891% (35614/50000)
11: 0.308101 | 21: 3.914334 | 12: 3.888137 | 22: 0.308101 | 1: 0.823696 | 2: 0.670357 | new: 1.494053 
Loss: 0.000001 | Accuracy: 0.909900% (9099/1000000)
best_accuracy: 0.9199

Epoch: 86
Loss: 0.945348 | Accuracy: 71.443719% (35721/50000)
11: 0.306839 | 21: 3.904981 | 12: 3.902167 | 22: 0.306839 | 1: 0.814242 | 2: 0.663303 | new: 1.477546 
Loss: 0.000001 | Accuracy: 0.913600% (9136/1000000)
best_accuracy: 0.9199

Epoch: 87
Loss: 0.934927 | Accuracy: 71.830391% (35915/50000)
11: 0.304707 | 21: 3.920065 | 12: 3.899593 | 22: 0.304707 | 1: 0.809390 | 2: 0.653473 | new: 1.462864 
Loss: 0.000001 | Accuracy: 0.907800% (9078/1000000)
best_accuracy: 0.9199

Epoch: 88
Loss: 0.943075 | Accuracy: 71.431758% (35715/50000)
11: 0.312664 | 21: 3.932640 | 12: 3.920435 | 22: 0.312664 | 1: 0.818625 | 2: 0.663753 | new: 1.482378 
Loss: 0.000001 | Accuracy: 0.889500% (8895/1000000)
best_accuracy: 0.9199

Epoch: 89
Loss: 0.970360 | Accuracy: 70.370344% (35185/50000)
11: 0.318410 | 21: 3.918216 | 12: 3.905532 | 22: 0.318410 | 1: 0.840106 | 2: 0.688023 | new: 1.528129 
Loss: 0.000001 | Accuracy: 0.902900% (9029/1000000)
best_accuracy: 0.9199

Epoch: 90
Loss: 0.965463 | Accuracy: 70.226344% (35113/50000)
11: 0.318387 | 21: 3.911079 | 12: 3.902016 | 22: 0.318387 | 1: 0.837577 | 2: 0.688909 | new: 1.526485 
Loss: 0.000001 | Accuracy: 0.912100% (9121/1000000)
best_accuracy: 0.9199

Epoch: 91
Loss: 0.952331 | Accuracy: 71.009789% (35504/50000)
11: 0.316389 | 21: 3.929882 | 12: 3.928451 | 22: 0.316389 | 1: 0.827108 | 2: 0.676624 | new: 1.503732 
Loss: 0.000001 | Accuracy: 0.908200% (9082/1000000)
best_accuracy: 0.9199

Epoch: 92
Loss: 0.967490 | Accuracy: 70.060422% (35030/50000)
11: 0.315437 | 21: 3.935171 | 12: 3.921874 | 22: 0.315437 | 1: 0.838089 | 2: 0.692033 | new: 1.530122 
Loss: 0.000001 | Accuracy: 0.897900% (8979/1000000)
best_accuracy: 0.9199

Epoch: 93
Loss: 0.984526 | Accuracy: 69.472695% (34736/50000)
11: 0.323901 | 21: 3.900019 | 12: 3.885274 | 22: 0.323901 | 1: 0.856114 | 2: 0.707635 | new: 1.563749 
Loss: 0.000001 | Accuracy: 0.874600% (8746/1000000)
best_accuracy: 0.9199

Epoch: 94
Loss: 0.941379 | Accuracy: 71.382391% (35691/50000)
11: 0.304838 | 21: 3.943395 | 12: 3.915223 | 22: 0.304838 | 1: 0.821548 | 2: 0.667999 | new: 1.489546 
Loss: 0.000001 | Accuracy: 0.886700% (8867/1000000)
best_accuracy: 0.9199

Epoch: 95
Loss: 0.926802 | Accuracy: 72.218461% (36109/50000)
11: 0.302615 | 21: 3.930958 | 12: 3.905014 | 22: 0.302615 | 1: 0.809277 | 2: 0.655150 | new: 1.464427 
Loss: 0.000001 | Accuracy: 0.904400% (9044/1000000)
best_accuracy: 0.9199

Epoch: 96
Loss: 0.966513 | Accuracy: 70.249781% (35124/50000)
11: 0.319480 | 21: 3.916378 | 12: 3.896662 | 22: 0.319480 | 1: 0.837824 | 2: 0.686322 | new: 1.524146 
Loss: 0.000001 | Accuracy: 0.916300% (9163/1000000)
best_accuracy: 0.9199

Epoch: 97
Loss: 0.959000 | Accuracy: 70.559305% (35279/50000)
11: 0.309643 | 21: 3.943857 | 12: 3.923481 | 22: 0.309643 | 1: 0.841224 | 2: 0.692939 | new: 1.534164 
Loss: 0.000001 | Accuracy: 0.915500% (9155/1000000)
best_accuracy: 0.9199

Epoch: 98
Loss: 0.926418 | Accuracy: 72.165234% (36082/50000)
11: 0.301650 | 21: 3.943743 | 12: 3.924215 | 22: 0.301650 | 1: 0.809531 | 2: 0.653944 | new: 1.463475 
Loss: 0.000001 | Accuracy: 0.922400% (9224/1000000)
Saving..
best_accuracy: 0.9224

Epoch: 99
Loss: 0.948733 | Accuracy: 70.808172% (35404/50000)
11: 0.310930 | 21: 3.912164 | 12: 3.884156 | 22: 0.310930 | 1: 0.826229 | 2: 0.674207 | new: 1.500436 
Loss: 0.000001 | Accuracy: 0.891700% (8917/1000000)
best_accuracy: 0.9224

Epoch: 100
Loss: 0.956204 | Accuracy: 70.809039% (35404/50000)
11: 0.309239 | 21: 3.924710 | 12: 3.908913 | 22: 0.309239 | 1: 0.833994 | 2: 0.684069 | new: 1.518063 
Loss: 0.000001 | Accuracy: 0.918300% (9183/1000000)
best_accuracy: 0.9224

Epoch: 101
Loss: 0.885692 | Accuracy: 72.857445% (36428/50000)
11: 0.244214 | 21: 3.995706 | 12: 3.995431 | 22: 0.244214 | 1: 0.807128 | 2: 0.688323 | new: 1.495451 
Loss: 0.000001 | Accuracy: 0.946800% (9468/1000000)
Saving..
best_accuracy: 0.9468

Epoch: 102
Loss: 0.859513 | Accuracy: 73.276000% (36638/50000)
11: 0.222275 | 21: 4.058867 | 12: 4.051932 | 22: 0.222275 | 1: 0.804308 | 2: 0.695757 | new: 1.500065 
Loss: 0.000001 | Accuracy: 0.946800% (9468/1000000)
best_accuracy: 0.9468

Epoch: 103
Loss: 0.842565 | Accuracy: 73.315117% (36657/50000)
11: 0.216275 | 21: 4.075576 | 12: 4.070896 | 22: 0.216275 | 1: 0.798361 | 2: 0.694935 | new: 1.493296 
Loss: 0.000001 | Accuracy: 0.948600% (9486/1000000)
Saving..
best_accuracy: 0.9486

Epoch: 104
Loss: 0.830129 | Accuracy: 74.042789% (37021/50000)
11: 0.206832 | 21: 4.097616 | 12: 4.094512 | 22: 0.206832 | 1: 0.794938 | 2: 0.693383 | new: 1.488320 
Loss: 0.000001 | Accuracy: 0.948800% (9488/1000000)
Saving..
best_accuracy: 0.9488

Epoch: 105
Loss: 0.843439 | Accuracy: 73.760563% (36880/50000)
11: 0.209936 | 21: 4.086003 | 12: 4.095588 | 22: 0.209936 | 1: 0.810236 | 2: 0.710072 | new: 1.520308 
Loss: 0.000001 | Accuracy: 0.948400% (9484/1000000)
best_accuracy: 0.9488

Epoch: 106
Loss: 0.813806 | Accuracy: 74.602016% (37301/50000)
11: 0.197124 | 21: 4.124205 | 12: 4.117861 | 22: 0.197124 | 1: 0.786659 | 2: 0.687783 | new: 1.474442 
Loss: 0.000001 | Accuracy: 0.949900% (9499/1000000)
Saving..
best_accuracy: 0.9499

Epoch: 107
Loss: 0.819839 | Accuracy: 73.990148% (36995/50000)
11: 0.197159 | 21: 4.121091 | 12: 4.115316 | 22: 0.197159 | 1: 0.793354 | 2: 0.696008 | new: 1.489361 
Loss: 0.000001 | Accuracy: 0.951500% (9515/1000000)
Saving..
best_accuracy: 0.9515

Epoch: 108
Loss: 0.828163 | Accuracy: 73.642289% (36821/50000)
11: 0.198968 | 21: 4.152035 | 12: 4.154686 | 22: 0.198968 | 1: 0.810078 | 2: 0.714930 | new: 1.525008 
Loss: 0.000001 | Accuracy: 0.952100% (9521/1000000)
Saving..
best_accuracy: 0.9521

Epoch: 109
Loss: 0.842366 | Accuracy: 72.628586% (36314/50000)
11: 0.200485 | 21: 4.153491 | 12: 4.147063 | 22: 0.200485 | 1: 0.824251 | 2: 0.732183 | new: 1.556433 
Loss: 0.000001 | Accuracy: 0.951800% (9518/1000000)
best_accuracy: 0.9521

Epoch: 110
Loss: 0.813133 | Accuracy: 73.975898% (36987/50000)
11: 0.191192 | 21: 4.152183 | 12: 4.160321 | 22: 0.191192 | 1: 0.798960 | 2: 0.708949 | new: 1.507909 
Loss: 0.000001 | Accuracy: 0.951300% (9513/1000000)
best_accuracy: 0.9521

Epoch: 111
Loss: 0.834414 | Accuracy: 73.107781% (36553/50000)
11: 0.196788 | 21: 4.163095 | 12: 4.151639 | 22: 0.196788 | 1: 0.822251 | 2: 0.728693 | new: 1.550945 
Loss: 0.000001 | Accuracy: 0.952500% (9525/1000000)
Saving..
best_accuracy: 0.9525

Epoch: 112
Loss: 0.769422 | Accuracy: 75.832078% (37916/50000)
11: 0.174892 | 21: 4.197670 | 12: 4.200531 | 22: 0.174892 | 1: 0.760128 | 2: 0.670260 | new: 1.430387 
Loss: 0.000001 | Accuracy: 0.952800% (9528/1000000)
Saving..
best_accuracy: 0.9528

Epoch: 113
Loss: 0.772248 | Accuracy: 76.001859% (38000/50000)
11: 0.175783 | 21: 4.195673 | 12: 4.195711 | 22: 0.175783 | 1: 0.767451 | 2: 0.676811 | new: 1.444261 
Loss: 0.000001 | Accuracy: 0.953500% (9535/1000000)
Saving..
best_accuracy: 0.9535

Epoch: 114
Loss: 0.815123 | Accuracy: 74.016172% (37008/50000)
11: 0.186922 | 21: 4.173442 | 12: 4.167729 | 22: 0.186922 | 1: 0.806551 | 2: 0.717132 | new: 1.523682 
Loss: 0.000001 | Accuracy: 0.950800% (9508/1000000)
best_accuracy: 0.9535

Epoch: 115
Loss: 0.800276 | Accuracy: 74.573156% (37286/50000)
11: 0.187467 | 21: 4.205168 | 12: 4.200985 | 22: 0.187467 | 1: 0.797182 | 2: 0.705121 | new: 1.502302 
Loss: 0.000001 | Accuracy: 0.955300% (9553/1000000)
Saving..
best_accuracy: 0.9553

Epoch: 116
Loss: 0.801331 | Accuracy: 74.691461% (37345/50000)
11: 0.181003 | 21: 4.215835 | 12: 4.210048 | 22: 0.181003 | 1: 0.797374 | 2: 0.706970 | new: 1.504344 
Loss: 0.000001 | Accuracy: 0.950500% (9505/1000000)
best_accuracy: 0.9553

Epoch: 117
Loss: 0.812109 | Accuracy: 73.862539% (36931/50000)
11: 0.187322 | 21: 4.213067 | 12: 4.217822 | 22: 0.187322 | 1: 0.817468 | 2: 0.729669 | new: 1.547137 
Loss: 0.000001 | Accuracy: 0.952600% (9526/1000000)
best_accuracy: 0.9553

Epoch: 118
Loss: 0.780839 | Accuracy: 75.649336% (37824/50000)
11: 0.173703 | 21: 4.219324 | 12: 4.220207 | 22: 0.173703 | 1: 0.779856 | 2: 0.691780 | new: 1.471636 
Loss: 0.000001 | Accuracy: 0.953200% (9532/1000000)
best_accuracy: 0.9553

Epoch: 119
Loss: 0.783460 | Accuracy: 75.219289% (37609/50000)
11: 0.173068 | 21: 4.224674 | 12: 4.220158 | 22: 0.173068 | 1: 0.786925 | 2: 0.698765 | new: 1.485690 
Loss: 0.000001 | Accuracy: 0.954400% (9544/1000000)
best_accuracy: 0.9553

Epoch: 120
Loss: 0.791715 | Accuracy: 74.482805% (37241/50000)
11: 0.175714 | 21: 4.221998 | 12: 4.226648 | 22: 0.175714 | 1: 0.796792 | 2: 0.712116 | new: 1.508908 
Loss: 0.000001 | Accuracy: 0.954200% (9542/1000000)
best_accuracy: 0.9553

Epoch: 121
Loss: 0.813640 | Accuracy: 73.673828% (36836/50000)
11: 0.180194 | 21: 4.229873 | 12: 4.226433 | 22: 0.180194 | 1: 0.819572 | 2: 0.735410 | new: 1.554981 
Loss: 0.000001 | Accuracy: 0.952300% (9523/1000000)
best_accuracy: 0.9553

Epoch: 122
Loss: 0.793851 | Accuracy: 74.577867% (37288/50000)
11: 0.177406 | 21: 4.241945 | 12: 4.244682 | 22: 0.177406 | 1: 0.803985 | 2: 0.717382 | new: 1.521367 
Loss: 0.000001 | Accuracy: 0.954300% (9543/1000000)
best_accuracy: 0.9553

Epoch: 123
Loss: 0.807509 | Accuracy: 74.085289% (37042/50000)
11: 0.178097 | 21: 4.243143 | 12: 4.249895 | 22: 0.178097 | 1: 0.818371 | 2: 0.733739 | new: 1.552110 
Loss: 0.000001 | Accuracy: 0.953700% (9537/1000000)
best_accuracy: 0.9553

Epoch: 124
Loss: 0.771460 | Accuracy: 75.529430% (37764/50000)
11: 0.168361 | 21: 4.233635 | 12: 4.226053 | 22: 0.168361 | 1: 0.776453 | 2: 0.690518 | new: 1.466971 
Loss: 0.000001 | Accuracy: 0.953400% (9534/1000000)
best_accuracy: 0.9553

Epoch: 125
Loss: 0.818929 | Accuracy: 73.316453% (36658/50000)
11: 0.182878 | 21: 4.215543 | 12: 4.213086 | 22: 0.182878 | 1: 0.827802 | 2: 0.743518 | new: 1.571320 
Loss: 0.000001 | Accuracy: 0.954600% (9546/1000000)
best_accuracy: 0.9553

Epoch: 126
Loss: 0.797783 | Accuracy: 74.478039% (37239/50000)
11: 0.175456 | 21: 4.213909 | 12: 4.208402 | 22: 0.175456 | 1: 0.803471 | 2: 0.718813 | new: 1.522284 
Loss: 0.000001 | Accuracy: 0.952800% (9528/1000000)
best_accuracy: 0.9553

Epoch: 127
Loss: 0.789428 | Accuracy: 74.848406% (37424/50000)
11: 0.171302 | 21: 4.240546 | 12: 4.234623 | 22: 0.171302 | 1: 0.805530 | 2: 0.721454 | new: 1.526984 
Loss: 0.000001 | Accuracy: 0.954600% (9546/1000000)
best_accuracy: 0.9553

Epoch: 128
Loss: 0.773570 | Accuracy: 75.378508% (37689/50000)
11: 0.166669 | 21: 4.235151 | 12: 4.238032 | 22: 0.166669 | 1: 0.785694 | 2: 0.703368 | new: 1.489062 
Loss: 0.000001 | Accuracy: 0.952500% (9525/1000000)
best_accuracy: 0.9553

Epoch: 129
Loss: 0.783154 | Accuracy: 74.861484% (37430/50000)
11: 0.168093 | 21: 4.247726 | 12: 4.242429 | 22: 0.168093 | 1: 0.797880 | 2: 0.715011 | new: 1.512891 
Loss: 0.000001 | Accuracy: 0.955200% (9552/1000000)
best_accuracy: 0.9553

Epoch: 130
Loss: 0.793339 | Accuracy: 74.232086% (37116/50000)
11: 0.172885 | 21: 4.238840 | 12: 4.252538 | 22: 0.172885 | 1: 0.807417 | 2: 0.728165 | new: 1.535583 
Loss: 0.000001 | Accuracy: 0.952900% (9529/1000000)
best_accuracy: 0.9553

Epoch: 131
Loss: 0.748988 | Accuracy: 76.169547% (38084/50000)
11: 0.160082 | 21: 4.278153 | 12: 4.269656 | 22: 0.160082 | 1: 0.767427 | 2: 0.683954 | new: 1.451382 
Loss: 0.000001 | Accuracy: 0.956400% (9564/1000000)
Saving..
best_accuracy: 0.9564

Epoch: 132
Loss: 0.790908 | Accuracy: 74.344742% (37172/50000)
11: 0.171918 | 21: 4.239545 | 12: 4.243099 | 22: 0.171918 | 1: 0.803660 | 2: 0.721420 | new: 1.525080 
Loss: 0.000001 | Accuracy: 0.954600% (9546/1000000)
best_accuracy: 0.9564

Epoch: 133
Loss: 0.780556 | Accuracy: 74.672461% (37336/50000)
11: 0.166670 | 21: 4.273886 | 12: 4.273095 | 22: 0.166670 | 1: 0.804270 | 2: 0.724469 | new: 1.528739 
Loss: 0.000001 | Accuracy: 0.954100% (9541/1000000)
best_accuracy: 0.9564

Epoch: 134
Loss: 0.803138 | Accuracy: 73.996422% (36998/50000)
11: 0.172204 | 21: 4.249019 | 12: 4.239307 | 22: 0.172204 | 1: 0.819112 | 2: 0.736770 | new: 1.555882 
Loss: 0.000001 | Accuracy: 0.953500% (9535/1000000)
best_accuracy: 0.9564

Epoch: 135
Loss: 0.768140 | Accuracy: 75.473148% (37736/50000)
11: 0.160493 | 21: 4.287361 | 12: 4.284359 | 22: 0.160493 | 1: 0.792357 | 2: 0.711836 | new: 1.504193 
Loss: 0.000001 | Accuracy: 0.954300% (9543/1000000)
best_accuracy: 0.9564

Epoch: 136
Loss: 0.771562 | Accuracy: 75.543195% (37771/50000)
11: 0.161536 | 21: 4.276816 | 12: 4.275843 | 22: 0.161536 | 1: 0.792735 | 2: 0.711955 | new: 1.504690 
Loss: 0.000001 | Accuracy: 0.955300% (9553/1000000)
best_accuracy: 0.9564

Epoch: 137
Loss: 0.809391 | Accuracy: 73.785875% (36892/50000)
11: 0.174611 | 21: 4.237714 | 12: 4.237783 | 22: 0.174611 | 1: 0.828076 | 2: 0.745656 | new: 1.573732 
Loss: 0.000001 | Accuracy: 0.950100% (9501/1000000)
best_accuracy: 0.9564

Epoch: 138
Loss: 0.804913 | Accuracy: 73.471750% (36735/50000)
11: 0.173031 | 21: 4.297209 | 12: 4.292407 | 22: 0.173031 | 1: 0.836184 | 2: 0.755517 | new: 1.591702 
Loss: 0.000001 | Accuracy: 0.953300% (9533/1000000)
best_accuracy: 0.9564

Epoch: 139
Loss: 0.775312 | Accuracy: 75.075156% (37537/50000)
11: 0.165890 | 21: 4.280421 | 12: 4.277513 | 22: 0.165890 | 1: 0.798302 | 2: 0.716008 | new: 1.514311 
Loss: 0.000001 | Accuracy: 0.956000% (9560/1000000)
best_accuracy: 0.9564

Epoch: 140
Loss: 0.784770 | Accuracy: 74.125828% (37062/50000)
11: 0.163952 | 21: 4.305055 | 12: 4.297121 | 22: 0.163952 | 1: 0.815902 | 2: 0.736857 | new: 1.552759 
Loss: 0.000001 | Accuracy: 0.953100% (9531/1000000)
best_accuracy: 0.9564

Epoch: 141
Loss: 0.754893 | Accuracy: 76.355625% (38177/50000)
11: 0.154849 | 21: 4.299439 | 12: 4.291040 | 22: 0.154849 | 1: 0.780900 | 2: 0.700379 | new: 1.481280 
Loss: 0.000001 | Accuracy: 0.954000% (9540/1000000)
best_accuracy: 0.9564

Epoch: 142
Loss: 0.784681 | Accuracy: 74.343508% (37171/50000)
11: 0.165437 | 21: 4.291508 | 12: 4.288502 | 22: 0.165437 | 1: 0.813998 | 2: 0.732849 | new: 1.546847 
Loss: 0.000001 | Accuracy: 0.956200% (9562/1000000)
best_accuracy: 0.9564

Epoch: 143
Loss: 0.769923 | Accuracy: 75.281680% (37640/50000)
11: 0.158689 | 21: 4.311082 | 12: 4.301042 | 22: 0.158689 | 1: 0.797655 | 2: 0.716969 | new: 1.514624 
Loss: 0.000001 | Accuracy: 0.954900% (9549/1000000)
best_accuracy: 0.9564

Epoch: 144
Loss: 0.774005 | Accuracy: 74.854484% (37427/50000)
11: 0.159263 | 21: 4.312543 | 12: 4.309110 | 22: 0.159263 | 1: 0.806155 | 2: 0.727032 | new: 1.533188 
Loss: 0.000001 | Accuracy: 0.957300% (9573/1000000)
Saving..
best_accuracy: 0.9573

Epoch: 145
Loss: 0.782581 | Accuracy: 74.546930% (37273/50000)
11: 0.162960 | 21: 4.281473 | 12: 4.281198 | 22: 0.162960 | 1: 0.813996 | 2: 0.734834 | new: 1.548829 
Loss: 0.000001 | Accuracy: 0.955700% (9557/1000000)
best_accuracy: 0.9573

Epoch: 146
Loss: 0.784224 | Accuracy: 74.573852% (37286/50000)
11: 0.162097 | 21: 4.315523 | 12: 4.310473 | 22: 0.162097 | 1: 0.819182 | 2: 0.739907 | new: 1.559088 
Loss: 0.000001 | Accuracy: 0.954100% (9541/1000000)
best_accuracy: 0.9573

Epoch: 147
Loss: 0.794382 | Accuracy: 73.773570% (36886/50000)
11: 0.164407 | 21: 4.339066 | 12: 4.330853 | 22: 0.164407 | 1: 0.835660 | 2: 0.757826 | new: 1.593487 
Loss: 0.000001 | Accuracy: 0.955600% (9556/1000000)
best_accuracy: 0.9573

Epoch: 148
Loss: 0.780448 | Accuracy: 74.511867% (37255/50000)
11: 0.160274 | 21: 4.360664 | 12: 4.357772 | 22: 0.160274 | 1: 0.823338 | 2: 0.745409 | new: 1.568747 
Loss: 0.000001 | Accuracy: 0.954300% (9543/1000000)
best_accuracy: 0.9573

Epoch: 149
Loss: 0.777678 | Accuracy: 74.538602% (37269/50000)
11: 0.157691 | 21: 4.353756 | 12: 4.352186 | 22: 0.157691 | 1: 0.819370 | 2: 0.743912 | new: 1.563282 
Loss: 0.000001 | Accuracy: 0.954900% (9549/1000000)
best_accuracy: 0.9573

Epoch: 150
Loss: 0.736852 | Accuracy: 76.468633% (38234/50000)
11: 0.146739 | 21: 4.357800 | 12: 4.347952 | 22: 0.146739 | 1: 0.772273 | 2: 0.695407 | new: 1.467679 
Loss: 0.000001 | Accuracy: 0.956400% (9564/1000000)
best_accuracy: 0.9573

Epoch: 151
Loss: 0.775253 | Accuracy: 74.214500% (37107/50000)
11: 0.152882 | 21: 4.345130 | 12: 4.339205 | 22: 0.152882 | 1: 0.819727 | 2: 0.745894 | new: 1.565621 
Loss: 0.000001 | Accuracy: 0.956400% (9564/1000000)
best_accuracy: 0.9573

Epoch: 152
Loss: 0.741389 | Accuracy: 76.161758% (38080/50000)
11: 0.143704 | 21: 4.362184 | 12: 4.366695 | 22: 0.143704 | 1: 0.790144 | 2: 0.717600 | new: 1.507745 
Loss: 0.000001 | Accuracy: 0.956500% (9565/1000000)
best_accuracy: 0.9573

Epoch: 153
Loss: 0.763136 | Accuracy: 75.257844% (37628/50000)
11: 0.149438 | 21: 4.351917 | 12: 4.353791 | 22: 0.149438 | 1: 0.811973 | 2: 0.739185 | new: 1.551158 
Loss: 0.000001 | Accuracy: 0.957600% (9576/1000000)
Saving..
best_accuracy: 0.9576

Epoch: 154
Loss: 0.791429 | Accuracy: 73.577187% (36788/50000)
11: 0.155735 | 21: 4.374469 | 12: 4.371369 | 22: 0.155735 | 1: 0.846923 | 2: 0.774989 | new: 1.621912 
Loss: 0.000001 | Accuracy: 0.956600% (9566/1000000)
best_accuracy: 0.9576

Epoch: 155
Loss: 0.738215 | Accuracy: 76.013070% (38006/50000)
11: 0.142085 | 21: 4.373327 | 12: 4.392549 | 22: 0.142085 | 1: 0.786257 | 2: 0.718586 | new: 1.504844 
Loss: 0.000001 | Accuracy: 0.956900% (9569/1000000)
best_accuracy: 0.9576

Epoch: 156
Loss: 0.770350 | Accuracy: 75.049188% (37524/50000)
11: 0.150818 | 21: 4.388243 | 12: 4.387627 | 22: 0.150818 | 1: 0.823658 | 2: 0.749942 | new: 1.573599 
Loss: 0.000001 | Accuracy: 0.956500% (9565/1000000)
best_accuracy: 0.9576

Epoch: 157
Loss: 0.761780 | Accuracy: 75.056719% (37528/50000)
11: 0.148078 | 21: 4.385560 | 12: 4.385583 | 22: 0.148078 | 1: 0.817873 | 2: 0.745800 | new: 1.563673 
Loss: 0.000001 | Accuracy: 0.954700% (9547/1000000)
best_accuracy: 0.9576

Epoch: 158
Loss: 0.730071 | Accuracy: 76.350633% (38175/50000)
11: 0.139670 | 21: 4.397982 | 12: 4.389297 | 22: 0.139670 | 1: 0.785232 | 2: 0.712328 | new: 1.497561 
Loss: 0.000001 | Accuracy: 0.957000% (9570/1000000)
best_accuracy: 0.9576

Epoch: 159
Loss: 0.780506 | Accuracy: 73.815203% (36907/50000)
11: 0.151680 | 21: 4.386811 | 12: 4.399204 | 22: 0.151680 | 1: 0.840384 | 2: 0.771858 | new: 1.612242 
Loss: 0.000001 | Accuracy: 0.955600% (9556/1000000)
best_accuracy: 0.9576

Epoch: 160
Loss: 0.779518 | Accuracy: 74.292977% (37146/50000)
11: 0.152438 | 21: 4.385509 | 12: 4.383875 | 22: 0.152438 | 1: 0.840662 | 2: 0.768988 | new: 1.609649 
Loss: 0.000001 | Accuracy: 0.957600% (9576/1000000)
best_accuracy: 0.9576

Epoch: 161
Loss: 0.775814 | Accuracy: 74.392547% (37196/50000)
11: 0.148851 | 21: 4.396565 | 12: 4.405169 | 22: 0.148851 | 1: 0.833030 | 2: 0.763303 | new: 1.596334 
Loss: 0.000001 | Accuracy: 0.957100% (9571/1000000)
best_accuracy: 0.9576

Epoch: 162
Loss: 0.751110 | Accuracy: 75.701164% (37850/50000)
11: 0.144290 | 21: 4.409407 | 12: 4.398025 | 22: 0.144290 | 1: 0.811897 | 2: 0.738213 | new: 1.550111 
Loss: 0.000001 | Accuracy: 0.957000% (9570/1000000)
best_accuracy: 0.9576

Epoch: 163
Loss: 0.780010 | Accuracy: 74.283172% (37141/50000)
11: 0.151077 | 21: 4.404150 | 12: 4.396535 | 22: 0.151077 | 1: 0.845693 | 2: 0.773109 | new: 1.618801 
Loss: 0.000001 | Accuracy: 0.957000% (9570/1000000)
best_accuracy: 0.9576

Epoch: 164
Loss: 0.771187 | Accuracy: 74.273562% (37136/50000)
11: 0.148414 | 21: 4.414963 | 12: 4.421095 | 22: 0.148414 | 1: 0.834678 | 2: 0.766672 | new: 1.601350 
Loss: 0.000001 | Accuracy: 0.956300% (9563/1000000)
best_accuracy: 0.9576

Epoch: 165
Loss: 0.765333 | Accuracy: 74.258516% (37129/50000)
11: 0.146074 | 21: 4.441679 | 12: 4.439623 | 22: 0.146074 | 1: 0.833856 | 2: 0.765598 | new: 1.599454 
Loss: 0.000001 | Accuracy: 0.956800% (9568/1000000)
best_accuracy: 0.9576

Epoch: 166
Loss: 0.746043 | Accuracy: 75.841469% (37920/50000)
11: 0.142440 | 21: 4.406921 | 12: 4.401020 | 22: 0.142440 | 1: 0.806152 | 2: 0.733765 | new: 1.539917 
Loss: 0.000001 | Accuracy: 0.956500% (9565/1000000)
best_accuracy: 0.9576

Epoch: 167
Loss: 0.748351 | Accuracy: 75.530172% (37765/50000)
11: 0.143303 | 21: 4.413894 | 12: 4.403322 | 22: 0.143303 | 1: 0.807094 | 2: 0.735450 | new: 1.542544 
Loss: 0.000001 | Accuracy: 0.956800% (9568/1000000)
best_accuracy: 0.9576

Epoch: 168
Loss: 0.745597 | Accuracy: 75.524078% (37762/50000)
11: 0.141608 | 21: 4.424685 | 12: 4.426828 | 22: 0.141608 | 1: 0.806825 | 2: 0.737379 | new: 1.544204 
Loss: 0.000001 | Accuracy: 0.956500% (9565/1000000)
best_accuracy: 0.9576

Epoch: 169
Loss: 0.770531 | Accuracy: 74.529148% (37264/50000)
11: 0.149244 | 21: 4.409011 | 12: 4.428332 | 22: 0.149244 | 1: 0.835073 | 2: 0.768803 | new: 1.603876 
Loss: 0.000001 | Accuracy: 0.956500% (9565/1000000)
best_accuracy: 0.9576

Epoch: 170
Loss: 0.762655 | Accuracy: 75.002344% (37501/50000)
11: 0.145825 | 21: 4.426786 | 12: 4.431055 | 22: 0.145825 | 1: 0.830553 | 2: 0.760519 | new: 1.591072 
Loss: 0.000001 | Accuracy: 0.957000% (9570/1000000)
best_accuracy: 0.9576

Epoch: 171
Loss: 0.747023 | Accuracy: 75.100688% (37550/50000)
11: 0.142399 | 21: 4.428354 | 12: 4.422334 | 22: 0.142399 | 1: 0.812739 | 2: 0.743203 | new: 1.555942 
Loss: 0.000001 | Accuracy: 0.959200% (9592/1000000)
Saving..
best_accuracy: 0.9592

Epoch: 172
Loss: 0.766050 | Accuracy: 74.563266% (37281/50000)
11: 0.146207 | 21: 4.407503 | 12: 4.410153 | 22: 0.146207 | 1: 0.831811 | 2: 0.763564 | new: 1.595375 
Loss: 0.000001 | Accuracy: 0.957000% (9570/1000000)
best_accuracy: 0.9592

Epoch: 173
Loss: 0.748155 | Accuracy: 75.714336% (37857/50000)
11: 0.144657 | 21: 4.390644 | 12: 4.386016 | 22: 0.144657 | 1: 0.805962 | 2: 0.733614 | new: 1.539577 
Loss: 0.000001 | Accuracy: 0.959100% (9591/1000000)
best_accuracy: 0.9592

Epoch: 174
Loss: 0.756929 | Accuracy: 75.456055% (37728/50000)
11: 0.144918 | 21: 4.403669 | 12: 4.405193 | 22: 0.144918 | 1: 0.813681 | 2: 0.743172 | new: 1.556853 
Loss: 0.000001 | Accuracy: 0.958300% (9583/1000000)
best_accuracy: 0.9592

Epoch: 175
Loss: 0.742460 | Accuracy: 75.914945% (37957/50000)
11: 0.141060 | 21: 4.398255 | 12: 4.393541 | 22: 0.141060 | 1: 0.801397 | 2: 0.730161 | new: 1.531558 
Loss: 0.000001 | Accuracy: 0.957200% (9572/1000000)
best_accuracy: 0.9592

Epoch: 176
Loss: 0.722640 | Accuracy: 76.416656% (38208/50000)
11: 0.134291 | 21: 4.447209 | 12: 4.430669 | 22: 0.134291 | 1: 0.787975 | 2: 0.717262 | new: 1.505237 
Loss: 0.000001 | Accuracy: 0.957000% (9570/1000000)
best_accuracy: 0.9592

Epoch: 177
Loss: 0.758196 | Accuracy: 74.707969% (37353/50000)
11: 0.147486 | 21: 4.410476 | 12: 4.409618 | 22: 0.147486 | 1: 0.825587 | 2: 0.756159 | new: 1.581746 
Loss: 0.000001 | Accuracy: 0.957500% (9575/1000000)
best_accuracy: 0.9592

Epoch: 178
Loss: 0.742185 | Accuracy: 75.632500% (37816/50000)
11: 0.142325 | 21: 4.408276 | 12: 4.408410 | 22: 0.142325 | 1: 0.805895 | 2: 0.736011 | new: 1.541905 
Loss: 0.000001 | Accuracy: 0.957500% (9575/1000000)
best_accuracy: 0.9592

Epoch: 179
Loss: 0.747098 | Accuracy: 75.481719% (37740/50000)
11: 0.141900 | 21: 4.414187 | 12: 4.415841 | 22: 0.141900 | 1: 0.809031 | 2: 0.740352 | new: 1.549384 
Loss: 0.000001 | Accuracy: 0.959100% (9591/1000000)
best_accuracy: 0.9592

Epoch: 180
srun: Force Terminated job 12114653
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: *** STEP 12114653.0 CANCELLED AT 2019-03-08T02:41:25 *** on svail-148
srun: error: svail-148: task 0: Terminated
nohup: ignoring input
==> Preparing data..
==> Resuming from checkpoint..
1
Using CUDA..

Epoch: 172
Loss: 0.978755 | Accuracy: 70.199891% (35099/50000)
11: 0.365369 | 21: 3.895336 | 12: 3.867967 | 22: 0.365369 | 1: 0.848768 | 2: 0.669436 | new: 1.518204 
train_research.py:247: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, targets = Variable(inputs, volatile=True), Variable(targets)
Loss: 0.000001 | Accuracy: 0.868500% (8685/1000000)
best_accuracy: 0.9592

Epoch: 173
srun: Force Terminated job 12115041
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: *** STEP 12115041.0 CANCELLED AT 2019-03-08T02:43:59 *** on svail-151
srun: error: svail-151: task 0: Terminated
nohup: ignoring input
==> Preparing data..
==> Resuming from checkpoint..
1
Using CUDA..

Epoch: 172
Loss: 0.980300 | Accuracy: 70.042031% (35021/50000)
11: 0.387303 | 21: 3.915800 | 12: 3.890389 | 22: 0.387303 | 1: 0.862902 | 2: 0.673335 | new: 1.536237 
train_research.py:247: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, targets = Variable(inputs, volatile=True), Variable(targets)
Loss: 0.004618 | Accuracy: 0.899700% (8997/1000000)
best_accuracy: 0.9592

Epoch: 173
Loss: 0.955559 | Accuracy: 70.612250% (35306/50000)
11: 0.299051 | 21: 3.847462 | 12: 3.843667 | 22: 0.299051 | 1: 0.821882 | 2: 0.681558 | new: 1.503439 
Loss: 0.003727 | Accuracy: 0.928000% (9280/1000000)
best_accuracy: 0.9592

Epoch: 174
Loss: 0.879011 | Accuracy: 73.430891% (36715/50000)
11: 0.260611 | 21: 3.900631 | 12: 3.906585 | 22: 0.260611 | 1: 0.778808 | 2: 0.645840 | new: 1.424648 
Loss: 0.003504 | Accuracy: 0.934800% (9348/1000000)
best_accuracy: 0.9592

Epoch: 175
Loss: 0.890175 | Accuracy: 72.528656% (36264/50000)
11: 0.256959 | 21: 3.916341 | 12: 3.907698 | 22: 0.256959 | 1: 0.802067 | 2: 0.676382 | new: 1.478449 
Loss: 0.003252 | Accuracy: 0.939700% (9397/1000000)
best_accuracy: 0.9592

Epoch: 176
srun: Force Terminated job 12115053
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: *** STEP 12115053.0 CANCELLED AT 2019-03-08T02:48:09 *** on svail-151
srun: error: svail-151: task 0: Terminated
nohup: ignoring input
==> Preparing data..
==> Resuming from checkpoint..
1
Using CUDA..

Epoch: 172
Loss: 1.000543 | Accuracy: 69.347055% (34673/50000)
11: 0.377397 | 21: 3.917997 | 12: 3.893655 | 22: 0.377397 | 1: 0.877030 | 2: 0.699940 | new: 1.576971 
train_research.py:247: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, targets = Variable(inputs, volatile=True), Variable(targets)
Loss: 0.465904 | Accuracy: 89.240000% (8924/10000)
Saving..
best_accuracy: 89.24

Epoch: 173
Loss: 0.947662 | Accuracy: 71.347047% (35673/50000)
11: 0.287072 | 21: 3.890624 | 12: 3.888477 | 22: 0.287072 | 1: 0.816857 | 2: 0.677231 | new: 1.494088 
Loss: 0.343744 | Accuracy: 93.030000% (9303/10000)
Saving..
best_accuracy: 93.03

Epoch: 174
Loss: 0.911365 | Accuracy: 72.237641% (36118/50000)
11: 0.259669 | 21: 3.915865 | 12: 3.913221 | 22: 0.259669 | 1: 0.801540 | 2: 0.674156 | new: 1.475696 
Loss: 0.354507 | Accuracy: 93.480000% (9348/10000)
Saving..
best_accuracy: 93.48

Epoch: 175
Loss: 0.886332 | Accuracy: 73.128250% (36564/50000)
11: 0.245344 | 21: 3.946090 | 12: 3.935356 | 22: 0.245344 | 1: 0.796362 | 2: 0.674246 | new: 1.470608 
Loss: 0.360959 | Accuracy: 93.800000% (9380/10000)
Saving..
best_accuracy: 93.8

Epoch: 176
Loss: 0.892591 | Accuracy: 72.739422% (36369/50000)
11: 0.242926 | 21: 3.963954 | 12: 3.952697 | 22: 0.242926 | 1: 0.811625 | 2: 0.693611 | new: 1.505236 
Loss: 0.362764 | Accuracy: 93.840000% (9384/10000)
Saving..
best_accuracy: 93.84

Epoch: 177
Loss: 0.897341 | Accuracy: 71.869906% (35934/50000)
11: 0.239894 | 21: 3.986333 | 12: 3.984617 | 22: 0.239894 | 1: 0.823906 | 2: 0.711735 | new: 1.535641 
Loss: 0.356690 | Accuracy: 93.930000% (9393/10000)
Saving..
best_accuracy: 93.93

Epoch: 178
Loss: 0.891136 | Accuracy: 71.749078% (35874/50000)
11: 0.236981 | 21: 4.006973 | 12: 4.004476 | 22: 0.236981 | 1: 0.825153 | 2: 0.716238 | new: 1.541391 
Loss: 0.298025 | Accuracy: 94.300000% (9430/10000)
Saving..
best_accuracy: 94.3

Epoch: 179
Loss: 0.827017 | Accuracy: 74.591219% (37295/50000)
11: 0.209628 | 21: 4.079506 | 12: 4.083370 | 22: 0.209628 | 1: 0.774787 | 2: 0.668654 | new: 1.443440 
Loss: 0.309981 | Accuracy: 94.330000% (9433/10000)
Saving..
best_accuracy: 94.33

Epoch: 180
Loss: 0.874501 | Accuracy: 72.701375% (36350/50000)
11: 0.223369 | 21: 4.054147 | 12: 4.048874 | 22: 0.223369 | 1: 0.822136 | 2: 0.715857 | new: 1.537993 
Loss: 0.320596 | Accuracy: 94.360000% (9436/10000)
Saving..
best_accuracy: 94.36

Epoch: 181
Loss: 0.853190 | Accuracy: 73.673766% (36836/50000)
11: 0.215600 | 21: 4.079202 | 12: 4.073237 | 22: 0.215600 | 1: 0.806959 | 2: 0.699730 | new: 1.506689 
Loss: 0.319609 | Accuracy: 94.490000% (9449/10000)
Saving..
best_accuracy: 94.49

Epoch: 182
Loss: 0.844787 | Accuracy: 73.702609% (36851/50000)
11: 0.212616 | 21: 4.076028 | 12: 4.080867 | 22: 0.212616 | 1: 0.802174 | 2: 0.699608 | new: 1.501782 
Loss: 0.275155 | Accuracy: 94.530000% (9453/10000)
Saving..
best_accuracy: 94.53

Epoch: 183
Loss: 0.863226 | Accuracy: 72.161633% (36080/50000)
11: 0.216524 | 21: 4.083137 | 12: 4.082124 | 22: 0.216524 | 1: 0.826195 | 2: 0.727323 | new: 1.553518 
Loss: 0.294030 | Accuracy: 94.610000% (9461/10000)
Saving..
best_accuracy: 94.61

Epoch: 184
Loss: 0.850737 | Accuracy: 73.243680% (36621/50000)
11: 0.210024 | 21: 4.119476 | 12: 4.113440 | 22: 0.210024 | 1: 0.817167 | 2: 0.716690 | new: 1.533858 
Loss: 0.290539 | Accuracy: 94.620000% (9462/10000)
Saving..
best_accuracy: 94.62

Epoch: 185
Loss: 0.835293 | Accuracy: 73.545633% (36772/50000)
11: 0.203197 | 21: 4.140224 | 12: 4.141976 | 22: 0.203197 | 1: 0.803841 | 2: 0.707274 | new: 1.511115 
Loss: 0.319227 | Accuracy: 94.570000% (9457/10000)
best_accuracy: 94.62

Epoch: 186
Loss: 0.807679 | Accuracy: 75.031641% (37515/50000)
11: 0.193525 | 21: 4.145818 | 12: 4.144450 | 22: 0.193525 | 1: 0.782863 | 2: 0.684504 | new: 1.467367 
Loss: 0.279224 | Accuracy: 94.900000% (9490/10000)
Saving..
best_accuracy: 94.9

Epoch: 187
Loss: 0.840330 | Accuracy: 73.347773% (36673/50000)
11: 0.202604 | 21: 4.119968 | 12: 4.117091 | 22: 0.202604 | 1: 0.811175 | 2: 0.715294 | new: 1.526468 
Loss: 0.316008 | Accuracy: 94.840000% (9484/10000)
best_accuracy: 94.9

Epoch: 188
Loss: 0.817367 | Accuracy: 74.510813% (37255/50000)
11: 0.195399 | 21: 4.150042 | 12: 4.155190 | 22: 0.195399 | 1: 0.793842 | 2: 0.699242 | new: 1.493084 
Loss: 0.301529 | Accuracy: 94.950000% (9495/10000)
Saving..
best_accuracy: 94.95

Epoch: 189
Loss: 0.832528 | Accuracy: 73.772055% (36886/50000)
11: 0.200384 | 21: 4.126938 | 12: 4.131084 | 22: 0.200384 | 1: 0.810880 | 2: 0.715440 | new: 1.526321 
Loss: 0.286931 | Accuracy: 94.950000% (9495/10000)
best_accuracy: 94.95

Epoch: 190
Loss: 0.786258 | Accuracy: 75.588539% (37794/50000)
11: 0.184874 | 21: 4.172745 | 12: 4.170255 | 22: 0.184874 | 1: 0.770766 | 2: 0.674965 | new: 1.445731 
Loss: 0.261019 | Accuracy: 95.040000% (9504/10000)
Saving..
best_accuracy: 95.04

Epoch: 191
Loss: 0.840194 | Accuracy: 72.986891% (36493/50000)
11: 0.199826 | 21: 4.147023 | 12: 4.140489 | 22: 0.199826 | 1: 0.823324 | 2: 0.729311 | new: 1.552635 
Loss: 0.280816 | Accuracy: 94.900000% (9490/10000)
best_accuracy: 95.04

Epoch: 192
Loss: 0.818918 | Accuracy: 74.470992% (37235/50000)
11: 0.190278 | 21: 4.184127 | 12: 4.176889 | 22: 0.190278 | 1: 0.804717 | 2: 0.710514 | new: 1.515231 
Loss: 0.291241 | Accuracy: 94.960000% (9496/10000)
best_accuracy: 95.04

Epoch: 193
Loss: 0.831690 | Accuracy: 73.096289% (36548/50000)
11: 0.196148 | 21: 4.171339 | 12: 4.167467 | 22: 0.196148 | 1: 0.819208 | 2: 0.726811 | new: 1.546019 
Loss: 0.286745 | Accuracy: 95.180000% (9518/10000)
Saving..
best_accuracy: 95.18

Epoch: 194
Loss: 0.802023 | Accuracy: 75.047391% (37523/50000)
11: 0.185144 | 21: 4.182804 | 12: 4.181650 | 22: 0.185144 | 1: 0.790840 | 2: 0.698637 | new: 1.489477 
Loss: 0.257556 | Accuracy: 95.190000% (9519/10000)
Saving..
best_accuracy: 95.19

Epoch: 195
Loss: 0.803561 | Accuracy: 74.536539% (37268/50000)
11: 0.184625 | 21: 4.184740 | 12: 4.187729 | 22: 0.184625 | 1: 0.796272 | 2: 0.706025 | new: 1.502297 
Loss: 0.308196 | Accuracy: 94.880000% (9488/10000)
best_accuracy: 95.19

Epoch: 196
Loss: 0.824366 | Accuracy: 73.574984% (36787/50000)
11: 0.192780 | 21: 4.171299 | 12: 4.171522 | 22: 0.192780 | 1: 0.816677 | 2: 0.726000 | new: 1.542677 
Loss: 0.287456 | Accuracy: 95.050000% (9505/10000)
best_accuracy: 95.19

Epoch: 197
Loss: 0.799631 | Accuracy: 74.501117% (37250/50000)
11: 0.182955 | 21: 4.197650 | 12: 4.199754 | 22: 0.182955 | 1: 0.794784 | 2: 0.706289 | new: 1.501074 
Loss: 0.299220 | Accuracy: 95.120000% (9512/10000)
best_accuracy: 95.19

Epoch: 198
Loss: 0.798271 | Accuracy: 74.732180% (37366/50000)
11: 0.183261 | 21: 4.207445 | 12: 4.200656 | 22: 0.183261 | 1: 0.792293 | 2: 0.702653 | new: 1.494946 
Loss: 0.292561 | Accuracy: 95.210000% (9521/10000)
Saving..
best_accuracy: 95.21

Epoch: 199
Loss: 0.802867 | Accuracy: 74.599203% (37299/50000)
11: 0.184111 | 21: 4.196826 | 12: 4.196041 | 22: 0.184111 | 1: 0.801306 | 2: 0.711602 | new: 1.512908 
Loss: 0.312747 | Accuracy: 95.060000% (9506/10000)
best_accuracy: 95.21

Epoch: 200
Loss: 0.810780 | Accuracy: 74.097641% (37048/50000)
11: 0.186812 | 21: 4.205534 | 12: 4.200260 | 22: 0.186812 | 1: 0.810972 | 2: 0.720729 | new: 1.531701 
Loss: 0.279854 | Accuracy: 95.050000% (9505/10000)
best_accuracy: 95.21

Epoch: 201
Loss: 0.794606 | Accuracy: 74.928758% (37464/50000)
11: 0.178899 | 21: 4.223010 | 12: 4.227683 | 22: 0.178899 | 1: 0.795603 | 2: 0.707042 | new: 1.502646 
Loss: 0.306358 | Accuracy: 95.030000% (9503/10000)
best_accuracy: 95.21

Epoch: 202
Loss: 0.803871 | Accuracy: 74.372547% (37186/50000)
11: 0.182424 | 21: 4.213635 | 12: 4.209435 | 22: 0.182424 | 1: 0.804601 | 2: 0.714012 | new: 1.518613 
Loss: 0.286926 | Accuracy: 95.090000% (9509/10000)
best_accuracy: 95.21

Epoch: 203
Loss: 0.804665 | Accuracy: 74.151031% (37075/50000)
11: 0.183101 | 21: 4.214040 | 12: 4.205939 | 22: 0.183101 | 1: 0.805382 | 2: 0.715773 | new: 1.521155 
Loss: 0.272400 | Accuracy: 95.200000% (9520/10000)
best_accuracy: 95.21

Epoch: 204
Loss: 0.827273 | Accuracy: 73.350102% (36675/50000)
11: 0.189746 | 21: 4.192299 | 12: 4.191268 | 22: 0.189746 | 1: 0.825745 | 2: 0.736080 | new: 1.561825 
Loss: 0.264229 | Accuracy: 95.260000% (9526/10000)
Saving..
best_accuracy: 95.26

Epoch: 205
Loss: 0.790171 | Accuracy: 75.172289% (37586/50000)
11: 0.178754 | 21: 4.210447 | 12: 4.211882 | 22: 0.178754 | 1: 0.790377 | 2: 0.700829 | new: 1.491207 
Loss: 0.246308 | Accuracy: 95.260000% (9526/10000)
best_accuracy: 95.26

Epoch: 206


